---
title: Technical Offering
date: 2021-11-01T15:32:40
draft: false
layout: 'page2'
---

## Tracking Exposed is a group of professional developers, researchers, and digital activist. We improve and maintain infrastructure to investigate the algorithms of:

- YouTube
- Facebook
- TikTok
- Amazon
- PornHub

Our tools enable audits and behavioral analyses of the different algorithms which run on these platforms.

We can parse and systematically collect various data types that are not available through official APIs, such as:

- Recommendations from feeds, sidebars, homepages, or auto-play
- Search results
- Sponsored content and advertisements

There are two main ways through which we can collect data for an algorithmic experiment:

#### Synthetic conditions

 * Automated bot accounts, which can be profiled to fit a particular demographic, political orientation or usage pattern, in order to observe the algorithmic response in a controlled environment.

#### Real-life conditions

* We have developed browser extensions which enable us to collect real-life data from volunteer users through data-donation campaigns. Participants can be recruited to be representative of specific groups of the population.


ðŸ’¡ Our infrastructure is language agnostic and operational to run experiments in almost any country around the world.


## Who we are

We are an informal group of professionals. We rely on a [not-for-profit organization](https://aiforensics.org/), or by other fiscal sponsor to build up partnership and support ongoing activities that might need our skills.

Our main mission is to build free software to enable research on recommender systems and hold platforms accountable in front of users and regulators.

Our team has more than five years of experience pioneering tools and techniques in the field of algorithmic transparency.

Our infrastructure and methodologies have been validated in several [peer-reviewed publications,](https://tracking.exposed/publications/) and our works have received coverage on [major media outlets](http://www.marcfaddoul.com/#in-the-news). Some of our reports have been cited in a [United Nations report](https://undocs.org/pdf?symbol=en/A/73/348), a house [testimony](https://www.ischool.berkeley.edu/news/2020/hany-farid-how-disinformation-dividing-nation) and a [US Congress official letter](https://malinowski.house.gov/sites/malinowski.house.gov/files/Letter%20to%20YouTube%20--%20Malinowski_Eshoo_final_0.pdf) to YouTube's CEO.

[Our code](https://github.com/tracking-exposed) is made available as free software, enabling anyone to scrutinize, reproduce or extend our methodologies.

Our work is supported by grants and by consulting missions, in which we support other organizations with specific data collection needs, or extend our infrastructure with custom features tailored to their objectives.

## Selected Use Cases

Algorithms have become the gatekeeper of most online resources. They select what users watch, read, or buy. There are rising concerns over the tremendous power wielded by these systems, which remain nonetheless extremely opaque.

Researchers, journalists and regulators are attempting to scrutinize these recommendation algorithms, but most investigations only rely on anecdotal evidence or inappropriate data.

Our mission is to empower data-driven investigations, based on large independent datasets. Here are a few examples of experiments that have been run with our infrastructure.

### Previous

**Investigating filter-bubbles on YouTube search**

* During the US 2020 elections, we observed how differently the YouTube search engine was behaving with right and left-leaning users searching for 'election results'.
* We found substantial differences, depicting a particularly pernicious filter-bubble: while customization is expected on recommended content, search results are widely expected by users to be 'objective'.

**Exposing the invisible curation of news content of the Facebook feed**

* This experiment was run in Argentina and [published](https://webfoundation.org/research/the-invisible-curation-of-content-facebooks-news-feed-and-our-information-diets/) in partnership with the World Wide Web Foundation. It measured how different news sources and stories were treated differently by the Facebook recommendation engine.

**A longitudinal analysis on YouTube's amplification of conspiratorial content**

* We ran an independent audit of YouTube's recommendation algorithm to verify the company's claim that they would start demoting conspiratorial content from their recommendations.
* More recently, our team carried analyses on YouTube's recommender in the context of the [COVID-19 Pandemic](https://link.springer.com/chapter/10.1007%2F978-3-030-76228-5_8).

**Election-integrity in Europe on Facebook**

* We aim to democratize AI transparency research including investigations into non-English content, which are often overlooked, despite being more vulnerable to exploits. We carried investigations on Facebook's algorithms during the [Dutch](https://policyreview.info/articles/news/political-advertising-exposed-tracking-facebook-ads-2021-dutch-elections/1543), [Italian](https://doi.org/10.1109/ASONAM.2018.8508659) and [French](https://medium.com/@trackingexposed/facebook-algorithm-and-impact-on-media-french-election-experiment-1-d760ed5a242f) elections.

**Educational resource for university projects**

* Every year, we participate at the winter school in Amsterdam University where students have the opportunity to carry an experiment on our infrastructure. Last year's focus was on Amazon, where [students looked](https://amazon.tracking.exposed/) at algorithmic price discriminations based on OS, gender or location. This year will be on TikTok.

## Active projects

#### Investigating political shadow-banning on TikTok and on YouTube.

* Despite [serious concerns](https://theintercept.com/2020/03/16/tiktok-app-moderators-users-discrimination/), there have been no large scale efforts to investigate and expose whether certain types of political speech are systematically censored on the platform.

#### Tracking advertising on kids videos on YouTube.

#### Investigating nonconsensual user-data processing on PornHub

#### Investigating unlawful algorithmic shift assignments for delivery workers
